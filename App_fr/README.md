# Langchain RAGBot

**Langchain RAGBot** est une application interactive **Streamlit** qui permet aux utilisateurs de poser des questions relatives au contenu de leurs documents en utilisant un pipeline de **Retrieval-Augmented Generation (RAG)** basÃ© sur des **LLM**.

## ğŸ“Œ AperÃ§u

Il sâ€™agit dâ€™un **RAG conversationnel** construit entiÃ¨rement Ã  partir de **modÃ¨les LLM et de modÃ¨les dâ€™embeddings open source**, pouvant Ãªtre facilement Ã©tendu Ã  des modÃ¨les plus puissants lorsque les ressources matÃ©rielles le permettent. Lâ€™objectif principal de cette application RAG est la **construction dâ€™un systÃ¨me de question-rÃ©ponse relativement au contenu de documents en langue franÃ§aise**. Ce modÃ¨le peut Ã©galement Ãªtre utilisÃ© avec des documents en **langue anglaise**.

Lâ€™application propose :
- La possibilitÃ© de tÃ©lÃ©verser des documents  
- Une interface conversationnelle pour interroger les documents  
- La sÃ©lection du modÃ¨le et des embeddings (modÃ¨les open source provenant de Hugging Face et dâ€™Ollama)  
- Un accÃ¨s transparent au contexte rÃ©cupÃ©rÃ© utilisÃ© pour gÃ©nÃ©rer les rÃ©ponses  
---

## ğŸš€ FonctionnalitÃ©s

### **1. Plusieurs LLM**
- Llama3 (quantifiÃ© q4_K_M) 8b  
- Llama3 8b  
- Mistral 7b  

### **2. Plusieurs modÃ¨les dâ€™embeddings**
- Paraphrase (sentence-transformers/paraphrase-multilingual-mpnet-base-v2)  
- Multilingual-e5 (intfloat/multilingual-e5-large)  
- Embedding franÃ§ais (dangvantuan/french-document-embedding)  

### **3. TÃ©lÃ©versement de documents**
- TÃ©lÃ©verser des documents et les interroger instantanÃ©ment  

### **4. Interface de chat interactive**
- Historique de conversations sauvegardÃ© dans lâ€™Ã©tat de session Streamlit  

### **5. RÃ©ponses en streaming**
- Les rÃ©ponses de lâ€™IA sont diffusÃ©es token par token pour une meilleure expÃ©rience par l'utilisateur  

### **6. Inspection du contexte**
- Visualisation des passages pertinents des documents rÃ©cupÃ©rÃ©s pour chaque question  

---

## ğŸ“ Structure du projet
```text
Langchain_RAGbot/App_fr
â”‚
â”œâ”€â”€ app.py                   # Application Streamlit principale
â”œâ”€â”€ utils.py                 # Fonctions utilitaires (crÃ©ation de lâ€™uploader de documents,
â”‚                            # du rÃ©cupÃ©rateur, de la chaÃ®ne RAG, etc.)
â”œâ”€â”€ streamlit_functions.py   # Fonctions utilitaires pour lâ€™application Streamlit
â”‚                            # (affichage de lâ€™uploader, messages du chat, etc.)
â”œâ”€â”€ create_db.py             # Script pour la crÃ©ation de la base de donnÃ©es Chroma
â”œâ”€â”€ requirement.txt          # Fichier contenant les dÃ©pendances requises
â”‚
â”œâ”€â”€ Chroma_store/            # Dossier contenant la base de donnÃ©es vectorielle
â”œâ”€â”€ Documents/               # Dossier contenant les fichiers de documents
â”‚
â”œâ”€â”€ images/                  # Images enregistrÃ©es : figures, icÃ´nes, captures dâ€™Ã©cran
â”‚   â””â”€â”€ example.png
â”‚
â””â”€â”€ README.md                # Documentation
```

## ğŸ› ï¸ Installation

### âš ï¸ PrÃ©requis
Avant de lancer lâ€™application, assurez-vous que les Ã©lÃ©ments suivants sont installÃ©s :
- Ollama est installÃ© et fonctionne sur votre systÃ¨me  
- Les modÃ¨les LLM requis sont tÃ©lÃ©chargÃ©s dans Ollama  
- Les modÃ¨les dâ€™embeddings requis sont tÃ©lÃ©chargÃ©s et disponibles  

Lâ€™application ne fonctionnera pas correctement si ces composants ne sont pas installÃ©s au prÃ©alable.

### ğŸ“¥ Cloner le dÃ©pÃ´t
```bash
git clone https://github.com/gitsujay25/Langchain_RAGbot.git
cd Langchain_RAGbot/App_fr
conda create -n langchain_rag python=3.10
conda activate langchain_rag
pip install -r requirements.txt
```
### â–¶ï¸ Lancer lâ€™application

```bash
streamlit run app.py
```
Le tableau de bord sâ€™ouvrira automatiquement dans votre navigateur Ã  lâ€™adresse : http://localhost:8501/

## ğŸ—ï¸ Disposition de lâ€™application

- **Barre latÃ©rale**
  - SÃ©lection du modÃ¨le LLM  
  - SÃ©lection du modÃ¨le dâ€™embedding  
  - TÃ©lÃ©versement de documents  
  - Option pour crÃ©er ou reconstruire le RAG  

- **Panneau central**
  - Interface de chat  
  - Saisie utilisateur et rÃ©ponses de lâ€™IA  

- **Panneau gauche**
  - Contexte rÃ©cupÃ©rÃ© liÃ© Ã  la requÃªte de lâ€™utilisateur

---

## â“ Comment lâ€™utiliser

1. SÃ©lectionnez un **modÃ¨le LLM** dans la barre latÃ©rale  
2. SÃ©lectionnez un **modÃ¨le dâ€™embedding**  
3. TÃ©lÃ©versez un ou plusieurs **documents**  
4. Appuyez sur le bouton **Build RAG** (ou **Rebuild RAG** â€“ lors de la reconstruction du RAG, toutes les conversations prÃ©cÃ©dentes seront supprimÃ©es et lâ€™application recommencera Ã  zÃ©ro)  
5. Posez une question via lâ€™interface de chat  
6. Recevez une **rÃ©ponse IA en streaming**  
7. Consultez le **contexte rÃ©cupÃ©rÃ©** dans le panneau de gauche

---

## ğŸ§° Conseils pour le dÃ©veloppement

- Conservez les fonctions rÃ©utilisables dans `utils.py`  
- Utilisez `streamlit_functions.py` pour les fonctions de construction de lâ€™interface Streamlit  
- Verrouillez les versions dans `requirements.txt` pour assurer la reproductibilitÃ©

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues !  
Nâ€™hÃ©sitez pas Ã  forker le dÃ©pÃ´t, ouvrir des issues ou soumettre des pull requests.

## ğŸ“¬ Contact
Pour toute question ou suggestion :  
- Auteur : Sujay Ray  
- GitHub : https://github.com/gitsujay25  
- LinkedIn : https://www.linkedin.com/in/sujayray92/